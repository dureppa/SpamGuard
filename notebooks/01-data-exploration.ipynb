{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a465c61-a74b-4207-8a9b-e55bc510ec54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные загружены. Размер: (5572, 2)\n",
      "\n",
      "Первые 3 строки:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"../data/raw/spam.csv\")\n",
    "df = pd.read_csv(data_path, encoding='latin-1')\n",
    "\n",
    "df = df.iloc[:, :2]\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "print(f\"Данные загружены. Размер: {df.shape}\")\n",
    "print(\"\\nПервые 3 строки:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38b68e3-84de-4a1c-acf6-bdbfa7be5486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Доля спама: 13.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Распределение классов:\")\n",
    "class_counts = df['label'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "spam_ratio = class_counts['spam'] / len(df)\n",
    "print(f\"\\nДоля спама: {spam_ratio:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3422569-e942-4664-b727-3e62be904cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример сообщения-спама:\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "Пример сообщения, не являющегося спамом:\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
     ]
    }
   ],
   "source": [
    "print(\"Пример сообщения-спама:\")\n",
    "print(df[df['label'] == 'spam']['message'].iloc[0])\n",
    "\n",
    "print(\"\\nПример сообщения, не являющегося спамом:\")\n",
    "print(df[df['label'] == 'ham']['message'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0009a21-bf3d-4c9d-97a2-0722014d182a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt', quiet=True)       \n",
    "nltk.download('stopwords', quiet=True)   \n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0288ebd0-9f11-4417-bc48-29a39fca4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v' \n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n' \n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r' \n",
    "    else:\n",
    "        return 'n'\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Предобработка текста с лемматизацией.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    \n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if w not in stop_words and len(w) >= 3]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f67bda-aa4e-4ebd-a4a8-61ec378b0d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст:\n",
      "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      "\n",
      "Очищенный текст:\n",
      "'jurong point crazy available bugis great world buffet cine get amore wat'\n",
      "\n",
      "Слова после обработки:\n",
      "['jurong', 'point', 'crazy', 'available', 'bugis', 'great', 'world', 'buffet', 'cine', 'get', 'amore', 'wat']\n"
     ]
    }
   ],
   "source": [
    "sample_message = df['message'].iloc[0]\n",
    "print(\"Исходный текст:\")\n",
    "print(repr(sample_message))\n",
    "\n",
    "print(\"\\nОчищенный текст:\")\n",
    "cleaned = clean_text(sample_message)\n",
    "print(repr(cleaned))\n",
    "\n",
    "print(\"\\nСлова после обработки:\")\n",
    "print(cleaned.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3a6d83-baf7-443d-b7c9-d1fc3a5df21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка завершена. Пример:\n",
      "                                             message  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "\n",
      "                                             cleaned  \n",
      "0  jurong point crazy available bugis great world...  \n",
      "1                                 lar joking wif oni  \n"
     ]
    }
   ],
   "source": [
    "df['cleaned'] = df['message'].apply(clean_text)\n",
    "print(\"Обработка завершена. Пример:\")\n",
    "print(df[['message', 'cleaned']].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60842075-bb35-4db3-9d42-224c15139c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь построен. Размер: 7246 слов\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "vocab = defaultdict(lambda: {'spam': 0, 'ham': 0})\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    label = row['label']\n",
    "    words = row['cleaned'].split()\n",
    "    for word in words:\n",
    "        vocab[word][label] += 1\n",
    "\n",
    "print(f\"Словарь построен. Размер: {len(vocab)} слов\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f40e306-1551-4136-aac0-e1c96aa0c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После фильтрации: 3231, до неё слов (было 7246)\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "filtered_vocab = {\n",
    "    word: counts\n",
    "    for word, counts in vocab.items()\n",
    "    if counts['spam'] + counts['ham'] >= MIN_FREQ\n",
    "}\n",
    "\n",
    "print(f\"После фильтрации: {len(filtered_vocab)}, до неё слов (было {len(vocab)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c29a7c1-b538-4ed0-a595-70bd85b24c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(spam) = 0.1341\n",
      "P(ham)  = 0.8659\n"
     ]
    }
   ],
   "source": [
    "total_spam = (df['label'] == 'spam').sum()\n",
    "total_ham = (df['label'] == 'ham').sum()\n",
    "total = len(df)\n",
    "\n",
    "p_spam = total_spam / total\n",
    "p_ham = total_ham / total\n",
    "\n",
    "print(f\"P(spam) = {p_spam:.4f}\")\n",
    "print(f\"P(ham)  = {p_ham:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bc36181-b673-4622-a84b-3a59749fb905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('free' | spam) = 0.017923\n",
      "P('free' | ham)  = 0.001744\n"
     ]
    }
   ],
   "source": [
    "V = len(filtered_vocab)\n",
    "\n",
    "def laplace_prob(count, total, V):\n",
    "    return (count + 1) / (total + V)\n",
    "\n",
    "total_words_spam = sum(counts['spam'] for counts in filtered_vocab.values())\n",
    "total_words_ham = sum(counts['ham'] for counts in filtered_vocab.values())\n",
    "\n",
    "word = \"free\"\n",
    "if word in filtered_vocab:\n",
    "    p_free_given_spam = laplace_prob(filtered_vocab[word]['spam'], total_words_spam, V)\n",
    "    p_free_given_ham  = laplace_prob(filtered_vocab[word]['ham'],  total_words_ham,  V)\n",
    "    print(f\"P('{word}' | spam) = {p_free_given_spam:.6f}\")\n",
    "    print(f\"P('{word}' | ham)  = {p_free_given_ham:.6f}\")\n",
    "else:\n",
    "    print(f\"Слово '{word}' отфильтровано или не встречается.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5356b0b-baee-442e-af9c-8de531ffa276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полный обработанный датасет сохранён: data/processed/spam_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "df.to_csv(\"../data/processed/spam_cleaned.csv\", index=False)\n",
    "print(\"Полный обработанный датасет сохранён: data/processed/spam_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b3c16a3-8013-4a90-9582-05b1f912f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4457 сообщений ({'ham': 3859, 'spam': 598})\n",
      "Test:  1115 сообщений ({'ham': 966, 'spam': 149})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(df_train)} сообщений ({df_train['label'].value_counts().to_dict()})\")\n",
    "print(f\"Test:  {len(df_test)} сообщений ({df_test['label'].value_counts().to_dict()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c2d566-d367-44d6-b366-ddf5f6f57425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train и test сохранены:\n",
      "- data/processed/train.csv\n",
      "- data/processed/test.csv\n"
     ]
    }
   ],
   "source": [
    "df_train.to_csv(\"../data/processed/train.csv\", index=False)\n",
    "df_test.to_csv(\"../data/processed/test.csv\", index=False)\n",
    "\n",
    "print(\"Train и test сохранены:\")\n",
    "print(\"- data/processed/train.csv\")\n",
    "print(\"- data/processed/test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spamguard",
   "language": "python",
   "name": "spamguard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
